# ml_fastVlm

This project is based on the [ml-fastvlm](https://github.com/apple/ml-fastvlm) repository by Apple.

## Original Repository

- **GitHub:** [https://github.com/apple/ml-fastvlm](https://github.com/apple/ml-fastvlm)

- **Description:**
  - ml-fastvlm is a fast and efficient implementation of Vision-Language Models (VLMs) developed by Apple. It provides tools and scripts for running, evaluating, and deploying VLMs for various machine learning and computer vision tasks.
  - The repository includes support for live camera prediction, interactive prediction, and other utilities for working with VLMs.

## Local Files

- `live_camera_predict.py`: Script for live camera-based predictions using the VLM.
- `live_interactive_predict.py`: Script for interactive predictions with user input.
- `live_interactive_quiet.py`: Variant of the interactive prediction script with reduced output or prompts.

## Usage

Refer to the original [ml-fastvlm GitHub repository](https://github.com/apple/ml-fastvlm) for detailed documentation, setup instructions, and usage examples.
